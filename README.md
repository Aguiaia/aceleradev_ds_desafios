# AceleraDev - Data Science - Desafios
##### Soluções encontradas para os desafios do AceleraDev Data Science

## Semana 2 - Pré processamento de dados em Python
###### Objetivo
O objetivo deste desafio é extrair algumas informações quantitativas que nos ajudem a compreender a natureza dos dados à disposição e ganhar alguns insights sobre o data set. Para isso, utilizaremos o data set Black Friday disponibilizado originalmente pela Analytics Vidhya e acessível publicamente através do Kaggle. O data set traz algumas variáveis relativas à transações comerciais realizadas durante a Black Friday em uma determinada loja de varejo. Cada observação é relativa a um determinado item comprado por um usuário e um usuário pode ter comprado mais de um item.

###### Tópicos
<ul>
  <li>Python</li>
  <li>Pandas</li>
  <li>Jupyter notebook</li> 
</ul>

## Semana 3 - Iniciando em estatística
###### Objetivo
Queremos conhecer melhor nossos clientes por estado. Para isso, iniciamos uma análise na pontuação de crédito. Para realizar a verificação inicial, precisamos de alguns valores. Os valores são a média, a mediana, a moda e o desvio padrão da pontuação de crédito.

## Semana 4 - Funções de probabilidade
###### Objetivo
O objetivo deste desafio é explorar as principais funções sobre distribuições de probabilidade como PDF, CDF e quantis e as relações entre duas das principais distribuições: a normal e a binomial.
Para isso, utilizaremos dados artificiais e reais. Como dados reais, exploraremos o data set Pulsar Star disponibilizado pelo Dr. Robert Lyon da Universidade de Manchester.Esse data set consiste de 8 variáveis a respeito de 17898 observações de estrelas. Essas estrelas foram consideradas “candidatas” a serem estrelas do tipo pulsar, que têm forte importância para os astrofísicos. Uma nona coluna do data set especifica se a estrela é realmente um pulsar (caso positivo, 1) ou não (caso negativo, 0).

###### Tópicos:

* Probabilidade
* Estatística
* NumPy
* SciPy
* StatsModels

## Semana 5 - Funções de probabilidade II

###### Objetivo
O objetivo deste desafio é explorar algumas funções de testes de hipóteses disponíveis em pacotes como o SciPy, aprendendo a interpretar seus resultados, ser crítico sobre seus usos e entender um pouco sobre seus funcionamentos. Para isso, utilizaremos o data set 2016 Olympics in Rio de Janeiro que consiste de 11 variáveis a respeito de 11538 atletas que participaram das Olimpíadas de 2016 no Rio de Janeiro.

###### Tópicos
* Probabilidade
* Estatística
* Testes de hipóteses
* Testes A/B

## Semana  6 - Redução de dimensionalidade e seleção de variáveis

###### Objetivo
O objetivo deste desafio é explorar sobre como funciona o PCA e como podemos obter data sets de dimensões mais baixas através dele. Para isso, vamos contar com o data set FIFA 2019 que contém originalmente 89 variáveis com diversos atributos de mais de 18 mil jogadores do game FIFA 2019.

###### Tópicos
* Redução de dimensionalidade
* PCA
* Seleção de variáveis
* RFE

## Semana 7 - Feature engineering
###### Objetivo
O objetivo deste desafio é adquirir conhecimento e prática nas ferramentas mais usuais de engenharia de variáveis. Com o domínio apropriado das técnicas básicas, como one-hot encoding, normalização e padroniação, o analista está mais bem preparado para conduzir uma etapa de preprocessamento dos dados que traga bons resultados da aplicação dos algoritmos de ML. Para isso, vamos contar com o data set Countries of the world que contém 20 variáveis, como população, área costeira e tamanho dos setores de produção, de 227 países.

###### Tópicos
* Feature engineering
* Processamento de texto

## Semana 8 - Prever a nota de matemática do ENEM
###### Objetivo:
Você deverá criar um modelo para prever a nota da prova de matemática de quem participou do ENEM 2016. Para isso, usará Python, Pandas, Sklearn e Regression.

###### Tópicos
* Python
* Pandas
* Sklearn
* Regression
